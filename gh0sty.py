#!/usr/bin/env python3
from colorama import Fore, Style
from gradio_client import Client
from gtts import gTTS
from presets import presets
from pydub import AudioSegment
from termcolor import colored
from tqdm import tqdm
import atexit
import glob
import huggingface-hub
import io
import json
import mpv
import openai
import os
import queue
import readline
def pthCompleter(text, state):
	line=readline.get_line_buffer().split()
	return [x+'/' if os.path.isdir(x) else x for x in glob.glob(text+'*')][:24][state]
readline.set_completer(pthCompleter)
readline.set_completer_delims('')
readline.parse_and_bind('tab: complete')
import requests
import subprocess
import sys
import tempfile
import termios
import time
import threading
import tty
sys.stdout=open(os.devnull, 'w')
import pygame
sys.stdout=sys.__stdout__

# openai pricing: https://openai.com/pricing
# stable diffusion pricing: https://stablediffusionapi.com/#pricing
# gpt: generative pretrained transformer
# token: text block which can be either a word, split word or char

lang='en' # tts language
#sys.stdout=open(os.devnull, 'w') # current musicgen link
#client=Client('https://facebook-musicgen.hf.space/')
#sys.stdout=sys.__stdout__

# for this chatbot to work a file called openai-api-key containing a valid
# openai api key needs to exist in this directory, and for stable diffusion
# to work, a stable-diffusion-api-key file as well, when the install.sh
# script is run it will copy the key over to ~/.local/share with the code

# GPT

# limits the length of the response, it has no affect on the prompt size
# limits which are affected by both the session history and the preset data
#maxTokens=1000 # no need to set this if it isnt being dynamically managed

# the default token limit here is 4096 tokens (aprx. $0.01 usd) for the
# gpt turbo model, output costs about +$0.003 usd (total=prompt+response)
model='gpt-3.5-turbo'

# randomness/spontaneity
# higher values increases the chance of the model selecting less probable
# tokens, while a lower value makes the model more likely to select the
# most probable tokens at each step of the response
temperature=0.6

# diversity/resourcefulness
# determines the level of diversity in the response using the cumulative
# token probability and influencing which tokens are considered at each
# step of the response, higher values increase diversity in the output
topP=0.7

# repetition/meticulousness
# penalises the selection of tokens that have already appeared in the
# response reducing the likelihood of repeating the same phrases, higher
# values will penalise repeated tokens more aggressively
frequencyPenalty=0.8

# relevance/attention
# penalises the generation of tokens not found in the input prompt,
# reducing the likelihood of introducing new ideas and making the output
# stick closer to the context provided
presencePenalty=0.2

# STABLE DIFFUSION

# note: stable diffusion will automatically store the generated image on
# one of their servers and it will be linked to the account that made the
# call, stable diffusion has a cheese pizza filter, prompts are logged in
# the api for traceability and are never deleted, please dont use this
# script for evil shit

sdWidth='512' # image width
sdHeight='512' # image height
negPrompt='badhandv4 easynegative lowres watermark unreadble'

# num images to be generated
sdSamples='1'

# num of diffusion steps to perform during generation, higher values
# increase quality, accepts 20, 30, 40 and 50
sdSteps='30'

# this is a flag to determine whether or not to perform nsfw or illegal
# safety checks on the generated image
sdSafetyCheck='no'

HOME=os.path.expanduser('~')
AUDDIR='/usr/share/Gh0sty/audio/'
IMGDIR='/usr/share/Gh0sty/images/'
RESPDIR='/tmp/gh0sty_response.mp3'
SPEEDUP='/tmp/gh0sty_sped.mp3'
SDAPIPATH='/usr/share/Gh0sty/keys/stable_diffusion_api_key'
SDAPIKEY=open(SDAPIPATH, 'r').read().strip()
OAAPIPATH='/usr/share/Gh0sty/keys/openai_api_key'
OAAPIKEY=open(OAAPIPATH, 'r').read().strip()
openai.api_key=OAAPIKEY

WHITE=Fore.WHITE
MAGENTA=Fore.MAGENTA
RED=Fore.RED
YELLOW=Fore.YELLOW
GREEN=Fore.GREEN
CYAN=Fore.CYAN
BLUE=Fore.BLUE
BLACK=Fore.BLACK

DIM=Style.DIM
NORMAL=Style.NORMAL
BOLD=Style.BRIGHT
RESET=Style.RESET_ALL

pygame.init()
pygame.mixer.init()
responseLck=threading.Lock()
responseQueue=queue.Queue()

def cleanup():
	pygame.mixer.quit()
	pygame.quit()
	os.system("killall -9 gh0sty &>'/dev/null'")

def printGpt():
	print(YELLOW+'â§¼â§¼ '+BOLD+'Chat GPT'+RESET+YELLOW+' â§½â§½'+RESET)

def reloadChat(responseLck, interrupt, presets, originalPresets):
	print(YELLOW+'*'+DIM+'reloaded'+RESET+YELLOW+'*'+RESET)
	pygame.mixer.music.stop()
	presets.clear()
	presets.extend(originalPresets)
	return interrupt

def printKeywords():
	print('â–¸'+BOLD+WHITE+' <exit-|ex-|e-> '+RESET+'leave the chat')
	print('â–¸'+BOLD+WHITE+' <keywords-|kw-|k-> '+RESET+'show this message')
	print('â–¸'+BOLD+WHITE+' <reload-|rl-|r-> '+RESET+'kill response and reset')
	print('â–¸'+BOLD+WHITE+' <image-|ig-|i-> '+RESET+'text to image (Stable Diffusion)')
	#print('â–¸'+BOLD+WHITE+' <music-|mc-|m-> '+RESET+'text to audio (MusicGen)')
	print('â–¸'+BOLD+WHITE+' <cancel-|rc-|c-> '+RESET+'return to text chat')

def genResponse(tempText, presets, gptParams, responseLck, interrupt, result):
	with open(tempText, 'r') as f:
		prompt=f.read()
	os.remove(tempText)
	message=presets+[{'role': 'user', 'content': prompt}]
	try:
		response=openai.ChatCompletion.create(
			model=model,
			messages=message,
			**gptParams)
		result.append(response['choices'][0]['message']['content'])
		gh0sty=response['choices'][0]['message']['content']
		playResponse(gh0sty, responseLck, interrupt)
		print(BOLD+GREEN+'GH0STY'+DIM+': '+RESET+gh0sty)
	except openai.error.RateLimitError:
		print(YELLOW+'*'+DIM+'tweaks spastically'+RESET+YELLOW+'*'+RESET)
		return None
	except openai.error.OpenAIError as e:
		print(YELLOW+'*'+DIM+'dies inside'+RESET+YELLOW+'*'+RESET)
		return None
	except Exception as e:
		print(BOLD+YELLOW+'âš  '+RESET+f'{e}'+YELLOW+BOLD+' âš '+RESET)
		return None

def playResponse(gh0sty, responseLck, interrupt):
	with responseLck:
		if interrupt:
			return
	tts=gTTS(text=gh0sty, lang=lang, slow=False)
	tts.save(RESPDIR)
	audio=AudioSegment.from_mp3(RESPDIR)
	speededUp=audio.speedup(playback_speed=1.3)
	speededUp.export(SPEEDUP, format='mp3')
	pygame.mixer.init()
	pygame.mixer.music.load(SPEEDUP)
	pygame.mixer.music.play()

def genSDImg(sdParams):
	print(YELLOW+'â§¼â§¼ '+BOLD+'Stable Diffusion'+RESET+YELLOW+' â§½â§½'+RESET)
	prompt=input(BOLD+BLUE+'PR0MPT'+DIM+': '+RESET)
	try:
		if prompt.lower() in ['cancel-', 'rc-', 'c-']:
			print(YELLOW+'*'+DIM+'cancelled'+RESET+YELLOW+'*'+RESET)
			printGpt()
			return
		with tqdm(total=100, bar_format=(
			BOLD+RED+'{l_bar}|ðŸ­®ðŸ®Š'+DIM+'{bar}'+RESET+BOLD+RED+'ðŸ®ŠðŸ­¬|{r_bar}')) as pbar:
			time.sleep(1)
			pbar.update(30)
			url='https://stablediffusionapi.com/api/v3/text2img'
			payload=json.dumps({
				'key': SDAPIKEY,
				'prompt': prompt,
				**sdParams})
			headers={'Content-Type': 'application/json'}
			time.sleep(1)
			pbar.update(30)
			response=requests.request('POST', url, headers=headers, data=payload)
			time.sleep(1)
			pbar.update(40)
		pbar.close()
		responseJson=response.json()
		imgPth=responseJson['output'][0]
		imgResponse=requests.get(imgPth, timeout=10)
		print(BOLD+BLUE+'URL'+DIM+': '+RESET+f'{imgPth}')
		with open('temp.png', 'wb') as f:
			f.write(imgResponse.content)
			if os.path.exists('temp.png'):
				os.system("qview temp.png &>'/dev/null'")
				os.remove('temp.png')
				saveImg(imgPth, imgResponse.content)
		printGpt()
	except requests.exceptions.RequestException as e:
		print(YELLOW+'*'+DIM+'tweaks spastically'+RESET+YELLOW+'*'+RESET)
		printGpt()
	except json.JSONDecodeError as e:
		print(YELLOW+'*'+DIM+'dies inside'+RESET+YELLOW+'*'+RESET)
		printGpt()
	except Exception as e:
		print(BOLD+YELLOW+'âš  '+RESET+f'{e}'+YELLOW+BOLD+' âš '+RESET)
		printGpt()

def saveImg(imgPth, imgData):
	saveResponse=input(BOLD+GREEN+'SAVE?'+DIM+': '+RESET).lower()
	if any(saveResponse.startswith(x) for x in [
		'1', 'y', 'ya', 'ye', 'ta', 'ok', 'pl', 'th']):
		imgName=input(BOLD+BLUE+'NAME'+DIM+': '+RESET)
		imgPth=os.path.join(IMGDIR, f'{imgName}.png')
		os.makedirs(os.path.dirname(imgPth), exist_ok=True)
		with open(imgPth, 'wb') as handler:
			handler.write(imgData)
		print(BOLD+GREEN+'SAVED AS'+DIM+': '+RESET+f'{imgPth}')

def genMusic():
	print(YELLOW+'â§¼â§¼ '+BOLD+'MusicGen'+RESET+YELLOW+' â§½â§½'+RESET)
	sampleFile=os.path.join(AUDDIR, 'sample1.wav')
	prompt=input(BOLD+BLUE+'PR0MPT'+DIM+': '+RESET)
	try:
		if prompt.lower() in ['cancel-', 'rc-', 'c-']:
			print(YELLOW+'*'+DIM+'cancelled'+RESET+YELLOW+'*'+RESET)
			printGpt()
			return
		with tqdm(total=100, bar_format=(
			BOLD+RED+'{l_bar}|ðŸ­®ðŸ®Š'+DIM+'{bar}'+RESET+BOLD+RED+'ðŸ®ŠðŸ­¬|{r_bar}')) as pbar:
			time.sleep(1)
			pbar.update(50)
			result=client.predict(prompt, sampleFile, fn_index=0)
			time.sleep(1)
			pbar.update(50)
			subprocess.run(['mpv', result],
				stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
		pbar.close()
		print(BOLD+BLUE+'URL'+DIM+': '+RESET+f'{result}')
		saveResponse=input(BOLD+GREEN+'SAVE?'+DIM+': '+RESET).lower()
		if any(saveResponse.startswith(x) for x in [
			'1', 'y', 'ya', 'ye', 'ta', 'ok', 'pl', 'th']):
			savePth=input(BOLD+BLUE+'SAVE AS'+DIM+': ')
			with open(savePth, 'wb') as f:
				f.write(result)
			print(BOLD+GREEN+'SAVED AS'+DIM+': '+RESET+f'{savePth}')
		printGpt()
	except Exception as e:
		print(BOLD+YELLOW+'âš  '+RESET+f'{e}'+YELLOW+BOLD+' âš '+RESET)
		printGpt()
		return None

def main():
	global interrupt
	atexit.register(cleanup)
	originalPresets=presets.copy()
	print('PROMPT: '+BOLD+WHITE+'hi-'+RESET)
	print(BOLD+WHITE+'<k-> '+RESET+'keywords'+RESET)
	print(YELLOW+'â§¼â§¼ '+BOLD+'Chat GPT'+RESET+YELLOW+' â§½â§½'+RESET)
	gptParams={
		'temperature': temperature,
		#'max_tokens': maxTokens,
		'top_p': topP,
		'frequency_penalty': frequencyPenalty,
		'presence_penalty': presencePenalty}
	sdParams={
		'width': sdWidth,
		'height': sdHeight,
		'negative_prompt': negPrompt,
		'samples': sdSamples,
		'num_inference_steps': sdSteps,
		'safety_checker': sdSafetyCheck}
	thread=None
	while True:
		if thread:
			thread.join()
		readline.set_completer_delims('')
		print(BOLD+BLUE+'PR0MPT'+DIM+': '+RESET, end='')
		usrInput='PR0MPT: '
		sys.stdout.flush()
		while True:
			char=sys.stdin.read(1)
			if (char == '\b' or char == '\x7f') and len(usrInput) > len('PR0MPT: '):
				usrInput=usrInput[:-1]
				sys.stdout.write('\b \b')
				sys.stdout.flush()
			else:
				usrInput += char
				sys.stdout.flush()
			if usrInput.endswith('-\n'):
				break
		readline.set_completer_delims(' \t\n')
		usrInput=usrInput[len('PR0MPT: '):].strip()
		if usrInput.lower() in ['exit-', 'ex-', 'e-']:
			break
		elif usrInput.lower() in ['keywords-', 'kw-', 'k-']:
			printKeywords()
		elif usrInput.lower() in ['reload-', 'rl-', 'r-']:
			with responseLck:
				interrupt=True
			interrupt=reloadChat(responseLck, interrupt, presets, originalPresets)
		elif usrInput.lower() in ['image-', 'ig-', 'i-']:
			genSDImg(sdParams)
		#elif usrInput.lower() in ['music-', 'mc-', 'm-']:
			#genMusic()
		else:
			with responseLck:
				interrupt=False
			presets.append({'role': 'user', 'content': usrInput})
			with tempfile.NamedTemporaryFile(delete=False) as temp:
				temp.write(usrInput.encode('utf-8'))
				tempText=temp.name
			try:
				result=[]
				thread=threading.Thread(
					target=genResponse, args=(
						tempText, presets, gptParams, responseLck, interrupt, result))
				thread.start()
				thread.join()
				response=result[0]
				presets.append({'role': 'system', 'content': response})
			except Exception as e:
				print(BOLD+YELLOW+'âš '+RESET+f' {e}'+YELLOW+BOLD+' âš ')

if __name__ == '__main__':
	main()
